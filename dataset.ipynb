{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "hyper_params = {\n",
    "    'model_name': 'distilroberta-base',\n",
    "    'weight_decay': 0.01,\n",
    "    'lr': 5e-5,\n",
    "    'batch_size': 8,\n",
    "    'gradient_accumulation': 16,\n",
    "    'epochs': 5,\n",
    "    \n",
    "    'balance_punctuation': False, \n",
    "    # if set to true, the number of <none> samples \n",
    "    # will be limited to the number of samples of\n",
    "    # the punctuation class with the max/mean/median number of samples\n",
    "    'balance_strategy': 'max',\n",
    "    \n",
    "    'lookahead': (0, 4),\n",
    "    # number of lookahead words (incl., incl.)\n",
    "    \n",
    "    'max_length': 32,\n",
    "    # maximum input vector size (after encoding)\n",
    "    \n",
    "    'truncate_left': True,\n",
    "    # if set to true, truncate to the given vector length\n",
    "    # removing left-side instead of right_side tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "udev             16G     0   16G   0% /dev\r\n",
      "tmpfs           3.2G  2.3M  3.2G   1% /run\r\n",
      "/dev/sda3       393G  306G   68G  82% /\r\n",
      "tmpfs            16G  236K   16G   1% /dev/shm\r\n",
      "tmpfs           5.0M     0  5.0M   0% /run/lock\r\n",
      "tmpfs            16G     0   16G   0% /sys/fs/cgroup\r\n",
      "/dev/loop2      100M  100M     0 100% /snap/core/10859\r\n",
      "/dev/loop3       56M   56M     0 100% /snap/core18/1988\r\n",
      "/dev/loop4       18M   18M     0 100% /snap/espanso/78\r\n",
      "/dev/loop9       92M   92M     0 100% /snap/go/7013\r\n",
      "/dev/loop6       18M   18M     0 100% /snap/espanso/84\r\n",
      "/dev/sdc6        98G  104M   98G   1% /boot/efi\r\n",
      "/dev/loop8      162M  162M     0 100% /snap/gnome-3-28-1804/128\r\n",
      "/dev/loop12     163M  163M     0 100% /snap/gnome-3-28-1804/145\r\n",
      "/dev/loop13      33M   33M     0 100% /snap/snapd/11107\r\n",
      "/dev/loop14      65M   65M     0 100% /snap/gtk-common-themes/1514\r\n",
      "/dev/loop15      65M   65M     0 100% /snap/gtk-common-themes/1513\r\n",
      "/dev/loop19      76M   76M     0 100% /snap/discord/121\r\n",
      "tmpfs           3.2G   20K  3.2G   1% /run/user/110\r\n",
      "tmpfs           3.2G   56K  3.2G   1% /run/user/1000\r\n",
      "/dev/loop20     157M  157M     0 100% /snap/code/59\r\n",
      "/dev/loop0       90M   90M     0 100% /snap/go/7221\r\n",
      "/dev/loop16     180M  180M     0 100% /snap/spotify/45\r\n",
      "/dev/loop17     180M  180M     0 100% /snap/spotify/46\r\n",
      "/dev/loop7      100M  100M     0 100% /snap/core/10908\r\n",
      "/dev/loop5       33M   33M     0 100% /snap/snapd/11402\r\n",
      "/dev/loop18      77M   77M     0 100% /snap/discord/122\r\n",
      "/dev/loop10      56M   56M     0 100% /snap/core18/1997\r\n",
      "/dev/loop11     200M  200M     0 100% /snap/code/60\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params['real_batch_size'] = hyper_params['batch_size'] * hyper_params['gradient_accumulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "p = SimpleNamespace(**hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset iwsl_t11/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/cdminix/.cache/huggingface/datasets/iwsl_t11/default/0.0.0/45c043923b095d0b7b755d9718080fab14dba3e3aceff44ffd9ed9a0f0e3fa7d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iwsl_t11 downloaded and prepared to /home/cdminix/.cache/huggingface/datasets/iwsl_t11/default/0.0.0/45c043923b095d0b7b755d9718080fab14dba3e3aceff44ffd9ed9a0f0e3fa7d. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('punctuation-iwslt2011/iwslt11.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'lookahead': 1,\n",
       " 'sentence_id': 2,\n",
       " 'text': \"and you would think that should have nothing to do with one another <comma> but i hope by the end of these 18 minutes <comma> you'll see a little bit of a relation <full_stop> what is <punct> origami\"}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6292, 29645)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds['validation']), len(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', fast=True, additional_special_tokens=['<punct>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(e):\n",
    "    result = tokenizer(\n",
    "        e['text'],\n",
    "        padding=True,\n",
    "        max_length=p.max_length,\n",
    "        pad_to_multiple_of=p.max_length,\n",
    "        truncation=(not p.truncate_left),\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    if len(result['input_ids'][0]) > p.max_length:\n",
    "        result['input_ids'] = np.concatenate(\n",
    "            [\n",
    "                [tokenizer.bos_token_id],\n",
    "                result['input_ids'][0][1:np.where(result['input_ids'][0]==tokenizer.eos_token_id)[0][0]][-(p.max_length-2):],\n",
    "                [tokenizer.eos_token_id]\n",
    "            ]\n",
    "        )\n",
    "        result['attention_mask'] = result['attention_mask'][0][:p.max_length]\n",
    "    else:\n",
    "        result['input_ids'] = result['input_ids'][0]\n",
    "        result['attention_mask'] = result['attention_mask'][0]\n",
    "    result['lookahead'] = e['lookahead']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c459790f72304763907f71e55a79e239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29645.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = ds.map(preprocess, batched=False)#, load_from_cache_file=False)\n",
    "dataset.rename_column_(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lookahead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'lookahead': Value(dtype='int32', id=None), 'sentence_id': Value(dtype='int32', id=None), 'text': Value(dtype='string', id=None), 'labels': ClassLabel(num_classes=4, names=['<full_stop>', '<comma>', '<question_mark>', '<none>'], names_file=None, id=None)}, num_rows: 6292)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset['train']\n",
    "valid = dataset['validation']\n",
    "#iwslt2011_train = dataset['iwslt11_train']\n",
    "train.shuffle(42)\n",
    "valid.shuffle(42)\n",
    "#iwslt2011_train.shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = iwslt2011_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "        p.model_name,\n",
    "        num_labels=4,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(p.model_name, config=config)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=streamed-automatic-punctuation-annotation\n",
      "env: WANDB_WATCH=all\n",
      "208374 1015304\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=streamed-automatic-punctuation-annotation\n",
    "%env WANDB_WATCH=all\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoConfig\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import wandb\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    num_punct_true = len([l for l in labels if l != 3])\n",
    "    num_punct_pred = len([p for p in predictions if p != 3])\n",
    "    num_punct_correct = np.sum([p==l for p,l in zip(labels,predictions) if l != 3])\n",
    "    metrics =  {\n",
    "        'precision': num_punct_correct / num_punct_pred,\n",
    "        'recall': num_punct_correct / num_punct_true,\n",
    "    }\n",
    "    metrics['f1'] = (2 * metrics['precision'] * metrics['recall'])/(metrics['precision']+metrics['recall'])\n",
    "    for name, f in zip(train.features['labels'].names, f1_score(labels, predictions, average=None)):\n",
    "        metrics[f'f1_{name}'] = f\n",
    "    for name, f in zip(train.features['labels'].names, precision_score(labels, predictions, average=None)):\n",
    "        metrics[f'precision_{name}'] = f\n",
    "    for name, f in zip(train.features['labels'].names, recall_score(labels, predictions, average=None)):\n",
    "        metrics[f'recall_{name}'] = f\n",
    "    return metrics\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                    # output directory\n",
    "    num_train_epochs=p.epochs,                 # total number of training epochs\n",
    "    per_device_train_batch_size=p.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=p.batch_size,   # batch size for evaluation\n",
    "    weight_decay=p.weight_decay,               # strength of weight decay\n",
    "    logging_dir='./logs',                      # directory for storing logs\n",
    "    logging_steps=500//p.gradient_accumulation,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    gradient_accumulation_steps=p.gradient_accumulation,\n",
    "    eval_steps=1000//p.gradient_accumulation,\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "        p.model_name,\n",
    "        num_labels=4,\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(p.model_name, config=config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "optimizer = AdamW(\n",
    "            [\n",
    "                {\"params\": model.base_model.parameters()},\n",
    "                {\"params\": model.classifier.parameters()},\n",
    "            ],\n",
    "            lr=p.lr,\n",
    "            weight_decay=p.weight_decay,\n",
    "        )\n",
    "\n",
    "if p.balance_punctuation:\n",
    "    if p.balance_strategy == 'max':\n",
    "        np_fun = np.max\n",
    "    if p.balance_strategy == 'mean':\n",
    "        np_fun = np.mean\n",
    "    if p.balance_strategy == 'median':\n",
    "        np_fun = np.median\n",
    "    mean_samples_excl_none = int(\n",
    "        np_fun(\n",
    "            sorted(np.unique(train['labels'], return_counts=True)[1])[:-1]\n",
    "        )\n",
    "    )\n",
    "    per_class_samples = mean_samples_excl_none\n",
    "else:\n",
    "    per_class_samples = float('inf')\n",
    "\n",
    "balanced_filter = np.concatenate(\n",
    "    [np.where(np.array(train['labels'])==i)[0][:per_class_samples] for i in range(4)],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(len(balanced_filter), len(train))\n",
    "\n",
    "total_steps = len(train.select(balanced_filter)) // p.real_batch_size\n",
    "total_steps = total_steps * p.epochs\n",
    "schedule = get_linear_schedule_with_warmup(\n",
    "     optimizer, total_steps // 2, total_steps\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                                      # the instantiated ğŸ¤— Transformers model to be trained\n",
    "    args=training_args,                               # training arguments, defined above\n",
    "    train_dataset=train.select(np.arange(100_000)),#balanced_filter),      # training dataset\n",
    "    eval_dataset=dataset['validation'].select(np.arange(1600)),       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, schedule),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3bb980c320419c9350badc6d0684c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6677d824ed54631afa09bcb22856713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12500.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2246841<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20210125_203424-o9myrbjp/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20210125_203424-o9myrbjp/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.41759</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>epoch</td><td>0.99021</td></tr><tr><td>total_flos</td><td>4938177461747712</td></tr><tr><td>_step</td><td>1612</td></tr><tr><td>_runtime</td><td>42774</td></tr><tr><td>_timestamp</td><td>1611649638</td></tr><tr><td>eval_loss</td><td>0.37529</td></tr><tr><td>eval_precision</td><td>0.4768</td></tr><tr><td>eval_recall</td><td>0.83333</td></tr><tr><td>eval_f1</td><td>0.60656</td></tr><tr><td>eval_f1_<full_stop></td><td>0.70758</td></tr><tr><td>eval_f1_<comma></td><td>0.52258</td></tr><tr><td>eval_f1_<question_mark></td><td>0.52174</td></tr><tr><td>eval_f1_<none></td><td>0.9305</td></tr><tr><td>eval_precision_<full_stop></td><td>0.59036</td></tr><tr><td>eval_precision_<comma></td><td>0.39512</td></tr><tr><td>eval_precision_<question_mark></td><td>0.35294</td></tr><tr><td>eval_precision_<none></td><td>0.99422</td></tr><tr><td>eval_recall_<full_stop></td><td>0.88288</td></tr><tr><td>eval_recall_<comma></td><td>0.77143</td></tr><tr><td>eval_recall_<question_mark></td><td>1.0</td></tr><tr><td>eval_recall_<none></td><td>0.87446</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–</td></tr><tr><td>learning_rate</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_flos</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_runtime</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ</td></tr><tr><td>eval_loss</td><td>â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–â–„â–ƒâ–‚â–ƒâ–…â–ƒâ–â–„â–‚â–ˆâ–ƒâ–…â–â–‚â–â–ƒâ–‚</td></tr><tr><td>eval_precision</td><td>â–‚â–†â–†â–†â–†â–†â–†â–ƒâ–ˆâ–„â–†â–†â–„â–„â–…â–…â–†â–…â–â–„â–„â–†â–†â–‡â–‡â–‡</td></tr><tr><td>eval_recall</td><td>â–â–…â–…â–‡â–‡â–†â–†â–…â–†â–„â–…â–…â–ƒâ–‡â–…â–„â–†â–‚â–†â–„â–†â–„â–…â–†â–ˆâ–†</td></tr><tr><td>eval_f1</td><td>â–â–…â–…â–‡â–†â–†â–†â–ƒâ–ˆâ–„â–†â–†â–ƒâ–„â–…â–…â–†â–„â–‚â–„â–„â–…â–†â–‡â–ˆâ–‡</td></tr><tr><td>eval_f1_<full_stop></td><td>â–â–‡â–†â–‡â–ˆâ–†â–†â–†â–‡â–…â–†â–ˆâ–…â–†â–…â–†â–…â–†â–†â–…â–…â–†â–†â–‡â–ˆâ–‡</td></tr><tr><td>eval_f1_<comma></td><td>â–ƒâ–„â–†â–†â–…â–†â–†â–ƒâ–ˆâ–…â–†â–…â–„â–„â–„â–„â–†â–„â–â–„â–ƒâ–†â–…â–†â–‡â–†</td></tr><tr><td>eval_f1_<question_mark></td><td>â–â–…â–ƒâ–…â–ˆâ–…â–„â–„â–…â–„â–‚â–„â–„â–…â–†â–„â–ƒâ–„â–‚â–†â–„â–…â–…â–„â–ƒâ–…</td></tr><tr><td>eval_f1_<none></td><td>â–†â–†â–‡â–†â–†â–†â–†â–„â–ˆâ–†â–‡â–†â–…â–ƒâ–…â–†â–†â–‡â–â–†â–„â–‡â–‡â–‡â–†â–‡</td></tr><tr><td>eval_precision_<full_stop></td><td>â–â–…â–‡â–†â–‡â–„â–…â–‡â–…â–…â–„â–ˆâ–†â–ƒâ–ƒâ–„â–‚â–‡â–„â–„â–ƒâ–†â–†â–…â–†â–†</td></tr><tr><td>eval_precision_<comma></td><td>â–„â–…â–…â–…â–„â–†â–†â–‚â–ˆâ–„â–†â–„â–ƒâ–ƒâ–…â–…â–‡â–„â–â–„â–„â–…â–…â–‡â–†â–†</td></tr><tr><td>eval_precision_<question_mark></td><td>â–â–„â–ƒâ–„â–ˆâ–„â–ƒâ–„â–„â–…â–‚â–„â–…â–„â–…â–„â–ƒâ–„â–â–…â–ƒâ–…â–„â–ƒâ–ƒâ–„</td></tr><tr><td>eval_precision_<none></td><td>â–…â–ƒâ–„â–†â–…â–…â–…â–…â–„â–†â–‚â–‚â–‚â–‡â–‚â–â–…â–â–ˆâ–‚â–…â–â–„â–„â–‡â–†</td></tr><tr><td>eval_recall_<full_stop></td><td>â–â–…â–‚â–…â–…â–…â–…â–â–†â–‚â–†â–ƒâ–â–‡â–‡â–†â–ˆâ–‚â–…â–ƒâ–ˆâ–‚â–„â–‡â–ˆâ–†</td></tr><tr><td>eval_recall_<comma></td><td>â–‚â–ƒâ–ˆâ–‡â–‡â–…â–…â–ˆâ–…â–‡â–‚â–‡â–†â–…â–‚â–â–‚â–„â–…â–„â–â–†â–…â–ƒâ–†â–…</td></tr><tr><td>eval_recall_<question_mark></td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–â–â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval_recall_<none></td><td>â–†â–†â–‡â–†â–†â–†â–†â–„â–ˆâ–†â–‡â–†â–…â–ƒâ–†â–†â–†â–‡â–â–†â–„â–‡â–‡â–‡â–†â–‡</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dauntless-field-59</strong>: <a href=\"https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation/runs/o9myrbjp\" target=\"_blank\">https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation/runs/o9myrbjp</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.5<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">clear-cherry-60</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation\" target=\"_blank\">https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation/runs/205z3m03\" target=\"_blank\">https://wandb.ai/cdminix/streamed-automatic-punctuation-annotation/runs/205z3m03</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20210126_082718-205z3m03</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2618675847207346, 'learning_rate': 1.9065190651906518e-06, 'epoch': 0.03968, 'total_flos': 94964951187456, 'step': 31}\n",
      "{'loss': 0.19425462907360447, 'learning_rate': 3.8130381303813035e-06, 'epoch': 0.07936, 'total_flos': 189929902374912, 'step': 62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca9c7484e104f32b59876fef2e5264d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20750800440786407, 'eval_precision': 0.6475409836065574, 'eval_recall': 0.7117117117117117, 'eval_f1': 0.6781115879828326, 'eval_f1_<full_stop>': 0.7413793103448275, 'eval_f1_<comma>': 0.608294930875576, 'eval_f1_<question_mark>': 0.7058823529411764, 'eval_f1_<none>': 0.9612289685442575, 'eval_precision_<full_stop>': 0.7107438016528925, 'eval_precision_<comma>': 0.5892857142857143, 'eval_precision_<question_mark>': 0.5454545454545454, 'eval_precision_<none>': 0.9690265486725663, 'eval_recall_<full_stop>': 0.7747747747747747, 'eval_recall_<comma>': 0.6285714285714286, 'eval_recall_<question_mark>': 1.0, 'eval_recall_<none>': 0.95355587808418, 'epoch': 0.07936, 'total_flos': 189929902374912, 'step': 62}\n",
      "{'loss': 0.17035542764971334, 'learning_rate': 5.7195571955719566e-06, 'epoch': 0.11904, 'total_flos': 284894853562368, 'step': 93}\n",
      "{'loss': 0.15409291175103956, 'learning_rate': 7.626076260762607e-06, 'epoch': 0.15872, 'total_flos': 379859804749824, 'step': 124}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbd0b6bdda1426c8192a559e3efe715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20380505094013643, 'eval_precision': 0.6814516129032258, 'eval_recall': 0.7612612612612613, 'eval_f1': 0.7191489361702127, 'eval_f1_<full_stop>': 0.7654320987654323, 'eval_f1_<comma>': 0.6666666666666666, 'eval_f1_<question_mark>': 0.7058823529411764, 'eval_f1_<none>': 0.9641025641025641, 'eval_precision_<full_stop>': 0.7045454545454546, 'eval_precision_<comma>': 0.6666666666666666, 'eval_precision_<question_mark>': 0.5454545454545454, 'eval_precision_<none>': 0.9733727810650887, 'eval_recall_<full_stop>': 0.8378378378378378, 'eval_recall_<comma>': 0.6666666666666666, 'eval_recall_<question_mark>': 1.0, 'eval_recall_<none>': 0.9550072568940493, 'epoch': 0.15872, 'total_flos': 379859804749824, 'step': 124}\n",
      "{'loss': 0.173797607421875, 'learning_rate': 9.53259532595326e-06, 'epoch': 0.1984, 'total_flos': 474824755937280, 'step': 155}\n",
      "{'loss': 0.17169884712465347, 'learning_rate': 1.1439114391143913e-05, 'epoch': 0.23808, 'total_flos': 569789707124736, 'step': 186}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcba733ba9bc4974a0110122d2554f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20039943854731973, 'eval_precision': 0.6624472573839663, 'eval_recall': 0.7072072072072072, 'eval_f1': 0.6840958605664488, 'eval_f1_<full_stop>': 0.7622950819672131, 'eval_f1_<comma>': 0.5918367346938775, 'eval_f1_<question_mark>': 0.631578947368421, 'eval_f1_<none>': 0.9616928128420285, 'eval_precision_<full_stop>': 0.6992481203007519, 'eval_precision_<comma>': 0.6373626373626373, 'eval_precision_<question_mark>': 0.46153846153846156, 'eval_precision_<none>': 0.966984592809978, 'eval_recall_<full_stop>': 0.8378378378378378, 'eval_recall_<comma>': 0.5523809523809524, 'eval_recall_<question_mark>': 1.0, 'eval_recall_<none>': 0.9564586357039188, 'epoch': 0.23808, 'total_flos': 569789707124736, 'step': 186}\n",
      "{'loss': 0.1887603267546623, 'learning_rate': 1.3345633456334564e-05, 'epoch': 0.27776, 'total_flos': 664754658312192, 'step': 217}\n",
      "{'loss': 0.17863919658045616, 'learning_rate': 1.5252152521525214e-05, 'epoch': 0.31744, 'total_flos': 759719609499648, 'step': 248}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdee4f0a2824483a92127377a991fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20259669938794103, 'eval_precision': 0.6723404255319149, 'eval_recall': 0.7117117117117117, 'eval_f1': 0.6914660831509846, 'eval_f1_<full_stop>': 0.7600000000000001, 'eval_f1_<comma>': 0.6, 'eval_f1_<question_mark>': 0.7058823529411764, 'eval_f1_<none>': 0.963908129784907, 'eval_precision_<full_stop>': 0.6834532374100719, 'eval_precision_<comma>': 0.6705882352941176, 'eval_precision_<question_mark>': 0.5454545454545454, 'eval_precision_<none>': 0.9684981684981685, 'eval_recall_<full_stop>': 0.8558558558558559, 'eval_recall_<comma>': 0.5428571428571428, 'eval_recall_<question_mark>': 1.0, 'eval_recall_<none>': 0.9593613933236574, 'epoch': 0.31744, 'total_flos': 759719609499648, 'step': 248}\n",
      "{'loss': 0.17545367825415828, 'learning_rate': 1.715867158671587e-05, 'epoch': 0.35712, 'total_flos': 854684560687104, 'step': 279}\n",
      "{'loss': 0.17313015845514113, 'learning_rate': 1.906519065190652e-05, 'epoch': 0.3968, 'total_flos': 949649511874560, 'step': 310}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be85798a6ed04bab81b6cf3d0f133d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.2043516612952226, 'eval_precision': 0.6711711711711712, 'eval_recall': 0.6711711711711712, 'eval_f1': 0.6711711711711712, 'eval_f1_<full_stop>': 0.75, 'eval_f1_<comma>': 0.5816326530612245, 'eval_f1_<question_mark>': 0.625, 'eval_f1_<none>': 0.9622641509433962, 'eval_precision_<full_stop>': 0.71900826446281, 'eval_precision_<comma>': 0.6263736263736264, 'eval_precision_<question_mark>': 0.5, 'eval_precision_<none>': 0.9622641509433962, 'eval_recall_<full_stop>': 0.7837837837837838, 'eval_recall_<comma>': 0.5428571428571428, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9622641509433962, 'epoch': 0.3968, 'total_flos': 949649511874560, 'step': 310}\n",
      "{'loss': 0.16670989990234375, 'learning_rate': 2.097170971709717e-05, 'epoch': 0.43648, 'total_flos': 1044614463062016, 'step': 341}\n",
      "{'loss': 0.1736696304813508, 'learning_rate': 2.2878228782287826e-05, 'epoch': 0.47616, 'total_flos': 1139579414249472, 'step': 372}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a596451b964d4db3b519e6987f3b6e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.21862438901152928, 'eval_precision': 0.632183908045977, 'eval_recall': 0.7432432432432432, 'eval_f1': 0.6832298136645962, 'eval_f1_<full_stop>': 0.7560975609756098, 'eval_f1_<comma>': 0.6055045871559633, 'eval_f1_<question_mark>': 0.631578947368421, 'eval_f1_<none>': 0.9620905410379094, 'eval_precision_<full_stop>': 0.6888888888888889, 'eval_precision_<comma>': 0.584070796460177, 'eval_precision_<question_mark>': 0.46153846153846156, 'eval_precision_<none>': 0.9761015683345781, 'eval_recall_<full_stop>': 0.8378378378378378, 'eval_recall_<comma>': 0.6285714285714286, 'eval_recall_<question_mark>': 1.0, 'eval_recall_<none>': 0.9484760522496372, 'epoch': 0.47616, 'total_flos': 1139579414249472, 'step': 372}\n",
      "{'loss': 0.15882947368006553, 'learning_rate': 2.4784747847478475e-05, 'epoch': 0.51584, 'total_flos': 1234544365436928, 'step': 403}\n",
      "{'loss': 0.1680999263640373, 'learning_rate': 2.6691266912669127e-05, 'epoch': 0.55552, 'total_flos': 1329509316624384, 'step': 434}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feecf2ab1ad84781a66fd9f858958176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20101858585636365, 'eval_precision': 0.679324894514768, 'eval_recall': 0.7252252252252253, 'eval_f1': 0.7015250544662309, 'eval_f1_<full_stop>': 0.7500000000000001, 'eval_f1_<comma>': 0.641711229946524, 'eval_f1_<question_mark>': 0.625, 'eval_f1_<none>': 0.9624224735497994, 'eval_precision_<full_stop>': 0.6620689655172414, 'eval_precision_<comma>': 0.7317073170731707, 'eval_precision_<question_mark>': 0.5, 'eval_precision_<none>': 0.9677182685253118, 'eval_recall_<full_stop>': 0.8648648648648649, 'eval_recall_<comma>': 0.5714285714285714, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9571843251088534, 'epoch': 0.55552, 'total_flos': 1329509316624384, 'step': 434}\n",
      "{'loss': 0.17941702565839213, 'learning_rate': 2.8597785977859783e-05, 'epoch': 0.5952, 'total_flos': 1424474267811840, 'step': 465}\n",
      "{'loss': 0.18000350459929434, 'learning_rate': 3.0504305043050428e-05, 'epoch': 0.63488, 'total_flos': 1519439218999296, 'step': 496}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6ae9ebafa744069899c75c5d0c17ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.20258089896975434, 'eval_precision': 0.6707818930041153, 'eval_recall': 0.7342342342342343, 'eval_f1': 0.7010752688172044, 'eval_f1_<full_stop>': 0.7578125, 'eval_f1_<comma>': 0.6224489795918368, 'eval_f1_<question_mark>': 0.7692307692307692, 'eval_f1_<none>': 0.9623400365630713, 'eval_precision_<full_stop>': 0.6689655172413793, 'eval_precision_<comma>': 0.6703296703296703, 'eval_precision_<question_mark>': 0.7142857142857143, 'eval_precision_<none>': 0.969786293294031, 'eval_recall_<full_stop>': 0.8738738738738738, 'eval_recall_<comma>': 0.580952380952381, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9550072568940493, 'epoch': 0.63488, 'total_flos': 1519439218999296, 'step': 496}\n",
      "{'loss': 0.17548394972278225, 'learning_rate': 3.2410824108241084e-05, 'epoch': 0.67456, 'total_flos': 1614404170186752, 'step': 527}\n",
      "{'loss': 0.17055806806010584, 'learning_rate': 3.431734317343174e-05, 'epoch': 0.71424, 'total_flos': 1709369121374208, 'step': 558}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc8c9ef49e24a39a5e64bacdd166d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.1990050203674764, 'eval_precision': 0.6495726495726496, 'eval_recall': 0.6846846846846847, 'eval_f1': 0.6666666666666666, 'eval_f1_<full_stop>': 0.726457399103139, 'eval_f1_<comma>': 0.611111111111111, 'eval_f1_<question_mark>': 0.5882352941176471, 'eval_f1_<none>': 0.9620991253644314, 'eval_precision_<full_stop>': 0.7232142857142857, 'eval_precision_<comma>': 0.5945945945945946, 'eval_precision_<question_mark>': 0.45454545454545453, 'eval_precision_<none>': 0.9663250366032211, 'eval_recall_<full_stop>': 0.7297297297297297, 'eval_recall_<comma>': 0.6285714285714286, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9579100145137881, 'epoch': 0.71424, 'total_flos': 1709369121374208, 'step': 558}\n",
      "{'loss': 0.18282564224735384, 'learning_rate': 3.622386223862239e-05, 'epoch': 0.75392, 'total_flos': 1804334072561664, 'step': 589}\n",
      "{'loss': 0.18434339954007056, 'learning_rate': 3.813038130381304e-05, 'epoch': 0.7936, 'total_flos': 1899299023749120, 'step': 620}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122d5cb3e4ed48cdbcb13df575ace2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.21334559300303227, 'eval_precision': 0.6455696202531646, 'eval_recall': 0.6891891891891891, 'eval_f1': 0.6666666666666666, 'eval_f1_<full_stop>': 0.7490039840637449, 'eval_f1_<comma>': 0.5837837837837838, 'eval_f1_<question_mark>': 0.4347826086956522, 'eval_f1_<none>': 0.9602334914264866, 'eval_precision_<full_stop>': 0.6714285714285714, 'eval_precision_<comma>': 0.675, 'eval_precision_<question_mark>': 0.29411764705882354, 'eval_precision_<none>': 0.9655172413793104, 'eval_recall_<full_stop>': 0.8468468468468469, 'eval_recall_<comma>': 0.5142857142857142, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9550072568940493, 'epoch': 0.7936, 'total_flos': 1899299023749120, 'step': 620}\n",
      "{'loss': 0.18273876559349797, 'learning_rate': 4.003690036900369e-05, 'epoch': 0.83328, 'total_flos': 1994263974936576, 'step': 651}\n",
      "{'loss': 0.19210126323084678, 'learning_rate': 4.194341943419434e-05, 'epoch': 0.87296, 'total_flos': 2089228926124032, 'step': 682}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44d3b497967426ab91f71a03a893a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.19729606815235456, 'eval_precision': 0.6741071428571429, 'eval_recall': 0.6801801801801802, 'eval_f1': 0.6771300448430494, 'eval_f1_<full_stop>': 0.7567567567567567, 'eval_f1_<comma>': 0.5990338164251208, 'eval_f1_<question_mark>': 0.5882352941176471, 'eval_f1_<none>': 0.962962962962963, 'eval_precision_<full_stop>': 0.7567567567567568, 'eval_precision_<comma>': 0.6078431372549019, 'eval_precision_<question_mark>': 0.45454545454545453, 'eval_precision_<none>': 0.9636627906976745, 'eval_recall_<full_stop>': 0.7567567567567568, 'eval_recall_<comma>': 0.5904761904761905, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9622641509433962, 'epoch': 0.87296, 'total_flos': 2089228926124032, 'step': 682}\n",
      "{'loss': 0.19846762380292338, 'learning_rate': 4.3849938499385e-05, 'epoch': 0.91264, 'total_flos': 2184193877311488, 'step': 713}\n",
      "{'loss': 0.1872583204700101, 'learning_rate': 4.575645756457565e-05, 'epoch': 0.95232, 'total_flos': 2279158828498944, 'step': 744}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c301f93960ab4500b9220b0b05fe88f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=200.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.21168884780141525, 'eval_precision': 0.6396761133603239, 'eval_recall': 0.7117117117117117, 'eval_f1': 0.6737739872068231, 'eval_f1_<full_stop>': 0.7131782945736435, 'eval_f1_<comma>': 0.6354166666666667, 'eval_f1_<question_mark>': 0.5263157894736842, 'eval_f1_<none>': 0.9637495422922007, 'eval_precision_<full_stop>': 0.6258503401360545, 'eval_precision_<comma>': 0.7011494252873564, 'eval_precision_<question_mark>': 0.38461538461538464, 'eval_precision_<none>': 0.9726533628972653, 'eval_recall_<full_stop>': 0.8288288288288288, 'eval_recall_<comma>': 0.580952380952381, 'eval_recall_<question_mark>': 0.8333333333333334, 'eval_recall_<none>': 0.9550072568940493, 'epoch': 0.95232, 'total_flos': 2279158828498944, 'step': 744}\n",
      "{'loss': 0.20276617234753025, 'learning_rate': 4.76629766297663e-05, 'epoch': 0.992, 'total_flos': 2374123779686400, 'step': 775}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=781, training_loss=0.18197090647132083)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(p.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = trainer.predict(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lookahead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead_test = []\n",
    "for i in range(5):\n",
    "    lookahead_test.append(dataset['test'].select(np.where(np.array(dataset['test']['lookahead'])==i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for l_test in lookahead_test:\n",
    "#    print(len(l_test))\n",
    "#    print(trainer.predict(l_test).metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead_valid = []\n",
    "for i in range(5):\n",
    "    lookahead_valid.append(dataset['validation'].select(np.where(np.array(dataset['validation']['lookahead'])==i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0e7a9886424eea8d47d04ce132369f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd927ac56c043ecac61cfdf09cf1d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1dac75477545cda0521fc83867c4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db73f28494da483497785b2956250934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df327344730416a87bceca3759eb1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "la_metrics = []\n",
    "for l_test in lookahead_test:\n",
    "    la_metrics.append(trainer.predict(l_test).metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in la_metrics[0].keys():\n",
    "    data = [[i, m[k]] for i, m in enumerate(la_metrics)]\n",
    "    table = wandb.Table(data=data, columns = [\"lookahead\", k])\n",
    "    wandb.log({f\"{k}_lookahead\" : wandb.plot.line(table, \"lookahead\", k, title=f\"{k} vs. lookahead\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35403078515318215, 'eval_precision': 0.3911917098445596, 'eval_recall': 0.5807692307692308, 'eval_f1': 0.4674922600619195, 'eval_f1_<full_stop>': 0.5265822784810127, 'eval_f1_<comma>': 0.37764350453172196, 'eval_f1_<question_mark>': 0.3516483516483517, 'eval_f1_<none>': 0.9243951612903225, 'eval_precision_<full_stop>': 0.39344262295081966, 'eval_precision_<comma>': 0.423728813559322, 'eval_precision_<question_mark>': 0.22857142857142856, 'eval_precision_<none>': 0.9610144623768602, 'eval_recall_<full_stop>': 0.7959183673469388, 'eval_recall_<comma>': 0.3405994550408719, 'eval_recall_<question_mark>': 0.7619047619047619, 'eval_recall_<none>': 0.8904641677995727}\n",
      "{'eval_loss': 0.20093342670284903, 'eval_precision': 0.633419689119171, 'eval_recall': 0.6269230769230769, 'eval_f1': 0.6301546391752577, 'eval_f1_<full_stop>': 0.7106481481481483, 'eval_f1_<comma>': 0.5290322580645161, 'eval_f1_<question_mark>': 0.5294117647058824, 'eval_f1_<none>': 0.9675916941587426, 'eval_precision_<full_stop>': 0.6504237288135594, 'eval_precision_<comma>': 0.6482213438735178, 'eval_precision_<question_mark>': 0.3829787234042553, 'eval_precision_<none>': 0.9668411867364747, 'eval_recall_<full_stop>': 0.7831632653061225, 'eval_recall_<comma>': 0.44686648501362397, 'eval_recall_<question_mark>': 0.8571428571428571, 'eval_recall_<none>': 0.9683433676442028}\n",
      "{'eval_loss': 0.16771832661593117, 'eval_precision': 0.6925064599483204, 'eval_recall': 0.6871794871794872, 'eval_f1': 0.6898326898326899, 'eval_f1_<full_stop>': 0.7797408716136631, 'eval_f1_<comma>': 0.5821596244131456, 'eval_f1_<question_mark>': 0.5757575757575758, 'eval_f1_<none>': 0.9734083850931676, 'eval_precision_<full_stop>': 0.7242888402625821, 'eval_precision_<comma>': 0.6838235294117647, 'eval_precision_<question_mark>': 0.4222222222222222, 'eval_precision_<none>': 0.9728419010669254, 'eval_recall_<full_stop>': 0.8443877551020408, 'eval_recall_<comma>': 0.5068119891008175, 'eval_recall_<question_mark>': 0.9047619047619048, 'eval_recall_<none>': 0.9739755292289765}\n",
      "{'eval_loss': 0.15397949678101416, 'eval_precision': 0.7300275482093664, 'eval_recall': 0.6794871794871795, 'eval_f1': 0.703851261620186, 'eval_f1_<full_stop>': 0.8154402895054281, 'eval_f1_<comma>': 0.5626016260162602, 'eval_f1_<question_mark>': 0.6129032258064516, 'eval_f1_<none>': 0.9741112828438948, 'eval_precision_<full_stop>': 0.7734553775743707, 'eval_precision_<comma>': 0.6975806451612904, 'eval_precision_<question_mark>': 0.4634146341463415, 'eval_precision_<none>': 0.9690563136651932, 'eval_recall_<full_stop>': 0.8622448979591837, 'eval_recall_<comma>': 0.4713896457765668, 'eval_recall_<question_mark>': 0.9047619047619048, 'eval_recall_<none>': 0.9792192658768692}\n",
      "{'eval_loss': 0.1466456494057467, 'eval_precision': 0.7443820224719101, 'eval_recall': 0.6794871794871795, 'eval_f1': 0.7104557640750669, 'eval_f1_<full_stop>': 0.8154402895054281, 'eval_f1_<comma>': 0.5757071547420965, 'eval_f1_<question_mark>': 0.6129032258064516, 'eval_f1_<none>': 0.9754968165155316, 'eval_precision_<full_stop>': 0.7734553775743707, 'eval_precision_<comma>': 0.7393162393162394, 'eval_precision_<question_mark>': 0.4634146341463415, 'eval_precision_<none>': 0.9691393521180756, 'eval_recall_<full_stop>': 0.8622448979591837, 'eval_recall_<comma>': 0.4713896457765668, 'eval_recall_<question_mark>': 0.9047619047619048, 'eval_recall_<none>': 0.981938240435036}\n"
     ]
    }
   ],
   "source": [
    "for metrics in la_metrics:\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 0 ----------\n",
      "COMMA 42.4 34.1 37.8\n",
      "PERIOD 39.3 79.6 52.7\n",
      "QUESTION 22.9 76.2 35.2\n",
      "OVERALL 39.1 58.1 46.7\n",
      "\n",
      "------- 1 ----------\n",
      "COMMA 64.8 44.7 52.9\n",
      "PERIOD 65.0 78.3 71.1\n",
      "QUESTION 38.3 85.7 52.9\n",
      "OVERALL 63.3 62.7 63.0\n",
      "\n",
      "------- 2 ----------\n",
      "COMMA 68.4 50.7 58.2\n",
      "PERIOD 72.4 84.4 78.0\n",
      "QUESTION 42.2 90.5 57.6\n",
      "OVERALL 69.3 68.7 69.0\n",
      "\n",
      "------- 3 ----------\n",
      "COMMA 69.8 47.1 56.3\n",
      "PERIOD 77.3 86.2 81.5\n",
      "QUESTION 46.3 90.5 61.3\n",
      "OVERALL 73.0 67.9 70.4\n",
      "\n",
      "------- 4 ----------\n",
      "COMMA 73.9 47.1 57.6\n",
      "PERIOD 77.3 86.2 81.5\n",
      "QUESTION 46.3 90.5 61.3\n",
      "OVERALL 74.4 67.9 71.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    res_dict = {key: round(val*100,1) for key, val in la_metrics[i].items()}\n",
    "    print(f'------- {i} ----------')\n",
    "    print('COMMA', res_dict['eval_precision_<comma>'], res_dict['eval_recall_<comma>'], res_dict['eval_f1_<comma>'])\n",
    "    print('PERIOD', res_dict['eval_precision_<full_stop>'], res_dict['eval_recall_<full_stop>'], res_dict['eval_f1_<full_stop>'])\n",
    "    print('QUESTION', res_dict['eval_precision_<question_mark>'], res_dict['eval_recall_<question_mark>'], res_dict['eval_f1_<question_mark>'])\n",
    "    print('OVERALL', res_dict['eval_precision'], res_dict['eval_recall'], res_dict['eval_f1'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29645"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test']['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6330049261083743"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4*60+29+3*60+58+3*60+27+2*60+53+2*60+21)/4/406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034677011300387924"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4*60+29+3*60+58+3*60+27+2*60+53+2*60+21)/29645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = trainer.model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96f9991c287446abef85a275fdbd8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=742.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-7aa5bf07afe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mla_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookahead_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mla_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     def prediction_loop(\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0mdisable_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_local_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                 \u001b[0;31m# The .mean() is to reduce in case of distributed training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         )\n\u001b[1;32m   1000\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         )\n\u001b[1;32m    677\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "la_metrics = []\n",
    "for l_test in lookahead_test:\n",
    "    la_metrics.append(trainer.predict(l_test).metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-27f10e5e3d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'embeddings'"
     ]
    }
   ],
   "source": [
    "trainer.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RobertaForSequenceClassification' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-5a5014ec519b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RobertaForSequenceClassification' object is not iterable"
     ]
    }
   ],
   "source": [
    "for d in trainer.model:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba680d683aab49d2b583f3b507dc4ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5929.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-306e56ce64e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookahead_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         )\n\u001b[1;32m   1000\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         )\n\u001b[1;32m    687\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                 )\n\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     ):\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/apaut/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for test in tqdm(lookahead_test[0]):\n",
    "    trainer.model.forward(torch.tensor([[0]*(512-32)+test['input_ids'].tolist()]), torch.tensor([[0]*(512-32)+test['attention_mask'].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2909428234103559"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((5*60+45)/5929)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0359251138471914"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((60*60)/5929)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.43478260869565"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((60*60)/5929)*5)/(((5*60+45)/5929)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
